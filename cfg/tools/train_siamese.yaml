#####################################
## THIS IS AN EXAMPLE TRAINING SCRIPT
#####################################

######################## TRAINING PARAMS ########################
num_epochs: 1
loss_margin: 1.0 # pretty important parameter, trade-off between training time and accuracy
optimizer:
  type: Adam # right now only one supported, TODO:(vsatish) Add support for more optimizers.
  # the following parameters will be optimizer-specific, check out build_optimizer() in SiameseTrainer for details
  lr: 0.0000001 # should be low for fine-tuning
tensorboard_port: 6006 # currently not used, TODO:(vsatish) Get automatic TensorBoard launch working.

bsz: 8 # this is probably not a great choice of bsz, but it allows this example to fit in 12GB DRAM x2 devices
num_prefetch_workers: 8 # at max number of logical cores

num_train_pairs: 1000
num_val_pairs: 100

shuffle_training_inputs: 1
data_augmentation_suffixes: [""]
allow_different_views: 1  

######################### NEIGHBORS PARAMS #####################

neighbor_classification: 1
dimension: 9984 # dimension of input npz files
distance: None # set to None for default
cache_dir: 
test_dir: 
num_neighbors: 10 # max number of neighbors to be returned by nearpy engine

######################### MODEL PARAMS #########################
siamese_net:
  network_mode: training # training or inference
  input_mode: feature # image or feature
  input_shape: [9984] # dim must match up with input_mode (3 for image, 1 for feature)
  num_gpus: 2 # number of GPUs to use, max 2 (1 for each input stream)

  architecture:
    ############################################
    # The generic format of the architecture is:
    # [] -> layer type
    # ... -> 1+
    # input_stream:
    #   ONE of the following if input_mode == "image":
    #   [resnet50f] resnet50fused with final fc layer cut off, can be randomly 
    #               initialized or loaded from pre-trained weights; if the latter, 
    #               can be fine-tuned or frozen
    #   OR
    #   [conv]
    #   .
    #   .
    #   .
    #
    #   Then OPTIONALLY (start here if input_mode == "feature", NO LONGER OPTIONAL; also 
    #   must have at least one of these if prev layer is resnet50f-this is because the 
    #   final layer of resnet50f has an activation applied, and we don't want our final 
    #   layer in the input_stream to have one):
    #   [fc] 
    #   .
    #   .
    #   .
    # merge_stream:
    #   ONE of the following:
    #   [l2] l2 norm
    #   OR
    #   [l1] l1 norm
    #   OR
    #   [fc] (fc layers can represent unknown distance 
    #         function, final layer must have out_size of 1)
    #   .
    #   .
    #   .
    ############################################
    input_stream: # main stream (duplicated) of siamese network
      res_net:  # weights/trainable necessary for resnet50f, out_size necessary for fc
        type: fc
        out_size: 512
#        weights: /nfs/diskstation/vsatish/dex-net/data/memory/models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5 # must be "random" or path to pre-trained *.h5 weights
#        trainable: 1 # fine-tuning


#      conv1_1:
#        type: conv
#        num_filt: 32
#        filt_dim: 8
#        pad: valid
#      conv1_2:
#        type: conv
#        num_filt: 32
#        filt_dim: 5
#        pad: valid
#      conv2_1:
#        type: conv
#        num_filt: 64
#        filt_dim: 3
#        pad: valid
#      conv2_2:
#        type: conv
#        num_filt: 64
#        filt_dim: 3
#        pad: valid
#      conv3_1:
#        type: conv
#        num_filt: 128
#        filt_dim: 3
#        pad: same
#      conv3_2:
#        type: conv
#        num_filt: 128
#        filt_dim: 3
#        pad: same
      fc_1:
        type: fc
        out_size: 256 
      fc_2:
        type: fc
        out_size: 128 # this will be our embedding vector size
    merge_stream: # can be fc layer(s) for generic distance function, or l1/l2
      l2_norm:
        type: fc
        out_size: 1

